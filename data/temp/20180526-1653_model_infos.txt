trainset_infos:
{'target_race': 'Man', 'length_of_sequence': 1, 'number_of_chars': 62, 'm': 3409}
m_training_infos:
{'total_epochs': 220, 'loss': 2.049544842441119, 'acc': 0.33118216490144076, 'trainset_infos': {'target_race': 'Man', 'length_of_sequence': 1, 'number_of_chars': 62, 'm': 3409}}
m_history["hyperparams"]:
[(0, {'lr': 0.0003, 'loss': 'categorical_crossentropy', 'batch_size': 32}), (120, {'lr': 0.0001, 'loss': 'categorical_crossentropy', 'batch_size': 32})]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_33 (InputLayer)        (None, 1, 62)             0         
_________________________________________________________________
lstm_11 (LSTM)               (None, 256)               326656    
_________________________________________________________________
dense_14 (Dense)             (None, 62)                15934     
_________________________________________________________________
activation_29 (Activation)   (None, 62)                0         
=================================================================
Total params: 342,590
Trainable params: 342,590
Non-trainable params: 0
_________________________________________________________________
